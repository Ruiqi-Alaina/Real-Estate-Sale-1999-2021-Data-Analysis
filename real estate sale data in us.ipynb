{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "67767197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6b00941b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"real_estate_data\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "531587b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  spark.read.csv(\"Real_Estate_Sales_2001-2020_GL.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "39a9131a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Serial Number='2020177', List Year='2020', Date Recorded='04/14/2021', Town='Ansonia', Address='323 BEAVER ST', Assessed Value='133000.00', Sale Amount='248400.00', Sales Ratio='0.5354', Property Type='Residential', Residential Type='Single Family', Non Use Code=None, Assessor Remarks=None, OPM remarks=None, Location='POINT (-73.06822 41.35014)'),\n",
       " Row(Serial Number='2020225', List Year='2020', Date Recorded='05/26/2021', Town='Ansonia', Address='152 JACKSON ST', Assessed Value='110500.00', Sale Amount='239900.00', Sales Ratio='0.4606', Property Type='Residential', Residential Type='Three Family', Non Use Code=None, Assessor Remarks=None, OPM remarks=None, Location=None),\n",
       " Row(Serial Number='2020348', List Year='2020', Date Recorded='09/13/2021', Town='Ansonia', Address='230 WAKELEE AVE', Assessed Value='150500.00', Sale Amount='325000.00', Sales Ratio='0.463', Property Type='Commercial', Residential Type=None, Non Use Code=None, Assessor Remarks=None, OPM remarks=None, Location=None),\n",
       " Row(Serial Number='2020090', List Year='2020', Date Recorded='12/14/2020', Town='Ansonia', Address='57 PLATT ST', Assessed Value='127400.00', Sale Amount='202500.00', Sales Ratio='0.6291', Property Type='Residential', Residential Type='Two Family', Non Use Code=None, Assessor Remarks=None, OPM remarks=None, Location=None),\n",
       " Row(Serial Number='200500', List Year='2020', Date Recorded='09/07/2021', Town='Avon', Address='245 NEW ROAD', Assessed Value='217640.00', Sale Amount='400000.00', Sales Ratio='0.5441', Property Type='Residential', Residential Type='Single Family', Non Use Code=None, Assessor Remarks=None, OPM remarks=None, Location=None)]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5855bb3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, Serial Number: string, List Year: string, Date Recorded: string, Town: string, Address: string, Assessed Value: string, Sale Amount: string, Sales Ratio: string, Property Type: string, Residential Type: string, Non Use Code: string, Assessor Remarks: string, OPM remarks: string, Location: string]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af93ef1c",
   "metadata": {},
   "source": [
    "# Questions for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5dd4f9",
   "metadata": {},
   "source": [
    "* Median and Average Sale Amount and Assessed Value in each town over the year\n",
    "* Overall Sale Amount and Assessed Value trend by years\n",
    "* The trend of Sale Amount median/average value for different property type \n",
    "* The trend of Sale Amount median/average value for different residental type <br>\n",
    "Note: we use recorded date for analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb9cef3",
   "metadata": {},
   "source": [
    "# Data cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894f1920",
   "metadata": {},
   "source": [
    "* Count the missing values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a21b72d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+-------------+----+-------+--------------+-----------+-----------+-------------+----------------+------------+----------------+-----------+--------+\n",
      "|Serial Number|List Year|Date Recorded|Town|Address|Assessed Value|Sale Amount|Sales Ratio|Property Type|Residential Type|Non Use Code|Assessor Remarks|OPM remarks|Location|\n",
      "+-------------+---------+-------------+----+-------+--------------+-----------+-----------+-------------+----------------+------------+----------------+-----------+--------+\n",
      "|            0|        0|            2|   0|     51|             1|          1|          1|       382447|          388310|      707532|          847343|     987240|  799521|\n",
      "+-------------+---------+-------------+----+-------+--------------+-----------+-----------+-------------+----------------+------------+----------------+-----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# count the missing value in each column\n",
    "from pyspark.sql.functions import col,when,count\n",
    "df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]\n",
    "   ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20452c08",
   "metadata": {},
   "source": [
    "* Drop the last four columns because of the large proportion of information loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7c5ff380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop Property Type, Residental Type, Non Use Code, Assessor Remarks, OPM remarks, Location for large amount of loss\n",
    "df = df.drop(\"Non Use Code\", \"Assessor Remarks\",\"OPM remarks\",\"Location\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0f63525d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+-------------+------------+--------------------+--------------+-----------+-----------+-------------+----------------+\n",
      "|Serial Number|List Year|Date Recorded|        Town|             Address|Assessed Value|Sale Amount|Sales Ratio|Property Type|Residential Type|\n",
      "+-------------+---------+-------------+------------+--------------------+--------------+-----------+-----------+-------------+----------------+\n",
      "|      2020177|     2020|   04/14/2021|     Ansonia|       323 BEAVER ST|     133000.00|  248400.00|     0.5354|  Residential|   Single Family|\n",
      "|      2020225|     2020|   05/26/2021|     Ansonia|      152 JACKSON ST|     110500.00|  239900.00|     0.4606|  Residential|    Three Family|\n",
      "|      2020348|     2020|   09/13/2021|     Ansonia|     230 WAKELEE AVE|     150500.00|  325000.00|      0.463|   Commercial|            NULL|\n",
      "|      2020090|     2020|   12/14/2020|     Ansonia|         57 PLATT ST|     127400.00|  202500.00|     0.6291|  Residential|      Two Family|\n",
      "|       200500|     2020|   09/07/2021|        Avon|        245 NEW ROAD|     217640.00|  400000.00|     0.5441|  Residential|   Single Family|\n",
      "|       200121|     2020|   12/15/2020|        Avon|        63 NORTHGATE|     528490.00|  775000.00|     0.6819|  Residential|   Single Family|\n",
      "|        20058|     2020|   06/01/2021| Barkhamsted|    46 RATLUM MTN RD|     203530.00|  415000.00|0.490433735|  Residential|   Single Family|\n",
      "|       200046|     2020|   01/25/2021|Beacon Falls|       34 LASKY ROAD|     158030.00|  243000.00|     0.6503|  Residential|   Single Family|\n",
      "|       200016|     2020|   11/13/2020|Beacon Falls|        9 AVON COURT|      65590.00|  100000.00|     0.6559|  Residential|           Condo|\n",
      "|      2020360|     2020|   08/10/2021|      Berlin|     94 PERCIVAL AVE|     140600.00|  190790.00|     0.7369|  Residential|   Single Family|\n",
      "|        20281|     2020|   04/21/2021|      Bethel|    16 OXFORD STREET|     170800.00|  307000.00|     0.5563|  Residential|   Single Family|\n",
      "|        20364|     2020|   06/17/2021|      Bethel|1308 LEXINGTON BO...|     195300.00|  365000.00|      0.535|  Residential|           Condo|\n",
      "|        20423|     2020|   07/21/2021|      Bethel| 10 CASTLE HILL ROAD|     219870.00|  325000.00|     0.6765|  Residential|   Single Family|\n",
      "|        20097|     2020|   11/25/2020|      Bethel|   8 BLACKMAN AVENUE|     264040.00|  445000.00|     0.5933|  Residential|      Two Family|\n",
      "|       200008|     2020|   10/21/2020|   Bethlehem|    34 HIGHLAND ROAD|      82000.00|  106000.00|     0.7735|  Residential|   Single Family|\n",
      "|        20062|     2020|   05/10/2021|      Bolton|    39 STONEHEDGE LN|     189400.00|  273750.00|     0.6918|  Residential|   Single Family|\n",
      "|       200305|     2020|   02/22/2021|    Branford|49 ROSE ST TOWERS...|      97800.00|  147000.00|     0.6653|  Residential|           Condo|\n",
      "|       200400|     2020|   04/08/2021|    Branford|         460 MAIN ST|     180500.00|  355000.00|     0.5084|  Residential|      Two Family|\n",
      "|       200423|     2020|   04/23/2021|    Branford|       24 COLLINS DR|     147000.00|  290000.00|     0.5068|  Residential|   Single Family|\n",
      "|       200483|     2020|   05/18/2021|    Branford|        61 PALMER RD|     219900.00|  460000.00|      0.478|  Residential|   Single Family|\n",
      "+-------------+---------+-------------+------------+--------------------+--------------+-----------+-----------+-------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82391551",
   "metadata": {},
   "source": [
    "* Drop the row where both 'Assessed Value' and 'Sale Amount' are missing and verify the outcome with count/when method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "76b7d0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+-------------+----+-------+--------------+-----------+-----------+-------------+----------------+\n",
      "|Serial Number|List Year|Date Recorded|Town|Address|Assessed Value|Sale Amount|Sales Ratio|Property Type|Residential Type|\n",
      "+-------------+---------+-------------+----+-------+--------------+-----------+-----------+-------------+----------------+\n",
      "|            0|        0|            2|   0|     51|             0|          0|          0|       382446|          388309|\n",
      "+-------------+---------+-------------+----+-------+--------------+-----------+-----------+-------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.filter(col('Assessed Value').isNotNull() & col('Sale Amount').isNotNull())\n",
    "df.select([count(when(col(c).isNull(),c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18427f8a",
   "metadata": {},
   "source": [
    "* Look into the rows where 'Date Recorded' is Null. And we found the some fo the 'Sale Amount'  Values are (or say smaller than the value 2000 mentioned in data description (https://catalog.data.gov/dataset/real-estate-sales-2001-2018))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "97e5e0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+-------------+------+-------+--------------+-----------+-----------+-------------+----------------+\n",
      "|Serial Number|List Year|Date Recorded|  Town|Address|Assessed Value|Sale Amount|Sales Ratio|Property Type|Residential Type|\n",
      "+-------------+---------+-------------+------+-------+--------------+-----------+-----------+-------------+----------------+\n",
      "|        20280|     2002|         NULL|Orange|   NULL|          0.00|       0.00|          0|         NULL|            NULL|\n",
      "|            0|     2002|         NULL|Orange|   NULL|          0.00|       0.00|          0|         NULL|            NULL|\n",
      "+-------------+---------+-------------+------+-------+--------------+-----------+-----------+-------------+----------------+\n",
      "\n",
      "+-------------+---------+-------------+---------+-------------------+--------------+-----------+-----------+-------------+----------------+\n",
      "|Serial Number|List Year|Date Recorded|     Town|            Address|Assessed Value|Sale Amount|Sales Ratio|Property Type|Residential Type|\n",
      "+-------------+---------+-------------+---------+-------------------+--------------+-----------+-----------+-------------+----------------+\n",
      "|        10703|     2001|   03/27/2002| Hartford|46-48 DEERFIELD AVE|      58030.00|       0.00|          0|         NULL|            NULL|\n",
      "|        10768|     2001|   04/11/2002| Hartford|   60 BURLINGTON ST|      54530.00|       0.00|          0|         NULL|            NULL|\n",
      "|        10445|     2001|   01/16/2002| Hartford|    486 CORNWALL ST|      51870.00|       0.00|          0|         NULL|            NULL|\n",
      "|        10179|     2001|   02/12/2002| Guilford|            GULL LN|      55580.00|       0.00|          0|         NULL|            NULL|\n",
      "|        10020|     2001|   11/07/2001|  Bethany|   168 BEAR HILL RD|     148010.00|       0.00|          0|         NULL|            NULL|\n",
      "|        10085|     2001|   04/17/2002|  Bethany|    17 CRESTWOOD RD|     126090.00|       0.00|          0|         NULL|            NULL|\n",
      "|        19007|     2001|   11/21/2001|  Bethany|        74 FALLS RD|     135520.00|       0.00|          0|         NULL|            NULL|\n",
      "|        10654|     2001|   02/14/2002|Stratford|       6905 MAIN ST|          0.00|       0.00|          0|         NULL|            NULL|\n",
      "|        11704|     2001|   08/23/2002|  Norwalk|    0 STRATHMORE LN|       6580.00|       0.00|          0|         NULL|            NULL|\n",
      "|        10393|     2001|   12/19/2001|Stratford|        34 TERRY PL|     111570.00|       0.00|          0|         NULL|            NULL|\n",
      "|        10646|     2001|   02/11/2002|Stratford|    801 BIRDSEYE ST|      62280.00|       0.00|          0|         NULL|            NULL|\n",
      "|        10482|     2001|   01/10/2002|Stratford|    129 BAYBERRY LN|     140390.00|       0.00|          0|         NULL|            NULL|\n",
      "|        10352|     2001|   12/10/2001|Stratford|    29 PRISCILLA LN|      46760.00|       0.00|          0|         NULL|            NULL|\n",
      "|        10631|     2001|   02/06/2002|Stratford|        503B OPA LN|     100140.00|       0.00|          0|         NULL|            NULL|\n",
      "|        10637|     2001|   02/07/2002|Stratford|       27 MCLEAN ST|      98660.00|       0.00|          0|         NULL|            NULL|\n",
      "|        10066|     2001|   10/31/2001|Newington|      60 STYLES AVE|      93870.00|       0.00|          0|         NULL|            NULL|\n",
      "|        10498|     2001|   01/14/2002|Stratford|      69 OAKLAND PL|      99360.00|       0.00|          0|         NULL|            NULL|\n",
      "|        20989|     2002|   07/24/2003|   Hamden|      230 BUTLER ST|      87570.00|       0.00|          0|         NULL|            NULL|\n",
      "|        20390|     2002|   01/21/2003|   Hamden|       35 SECOND ST|      91350.00|       0.00|          0|         NULL|            NULL|\n",
      "|        20170|     2002|   07/18/2003|   Putnam|      45 MAYNARD ST|      50000.00|       0.00|          0|         NULL|            NULL|\n",
      "+-------------+---------+-------------+---------+-------------------+--------------+-----------+-----------+-------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(col('Date Recorded').isNull()).show()\n",
    "df.filter(col('Sale Amount')==0).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415367bf",
   "metadata": {},
   "source": [
    "* Check and drop rows where 'Sale Amount' is smaller than 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "03c62b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|Sale Amount|\n",
      "+-----------+\n",
      "|       2139|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(count(when(col('Sale Amount')<2000,'Sale Amount')).alias(\"Sale Amount\")).show()\n",
    "df = df.filter(col('Sale Amount')>=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0903adc5",
   "metadata": {},
   "source": [
    "* Verify the outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0cd6407e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|Sale Amount|\n",
      "+-----------+\n",
      "|          0|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# verify\n",
    "df.select(count(when(col('Sale Amount')<2000,'Sale Amount')).alias(\"Sale Amount\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8c88af",
   "metadata": {},
   "source": [
    "* Check if there are replicated rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "af5157b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check replicated value (No if True)\n",
    "df.distinct().count()==df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ff7f6b",
   "metadata": {},
   "source": [
    "* To use the recorded year for analysis, we need to extract year out from the recorded date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c143765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year \n",
    "from pyspark.sql.functions import to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a1d9b991",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('Recorded Year',year(to_date(col('Date Recorded'),'MM/dd/yyyy')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b49b52fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+-------------+------------+--------------------+--------------+-----------+-----------+-------------+----------------+-------------+\n",
      "|Serial Number|List Year|Date Recorded|        Town|             Address|Assessed Value|Sale Amount|Sales Ratio|Property Type|Residential Type|Recorded Year|\n",
      "+-------------+---------+-------------+------------+--------------------+--------------+-----------+-----------+-------------+----------------+-------------+\n",
      "|      2020177|     2020|   04/14/2021|     Ansonia|       323 BEAVER ST|     133000.00|  248400.00|     0.5354|  Residential|   Single Family|         2021|\n",
      "|      2020225|     2020|   05/26/2021|     Ansonia|      152 JACKSON ST|     110500.00|  239900.00|     0.4606|  Residential|    Three Family|         2021|\n",
      "|      2020348|     2020|   09/13/2021|     Ansonia|     230 WAKELEE AVE|     150500.00|  325000.00|      0.463|   Commercial|            NULL|         2021|\n",
      "|      2020090|     2020|   12/14/2020|     Ansonia|         57 PLATT ST|     127400.00|  202500.00|     0.6291|  Residential|      Two Family|         2020|\n",
      "|       200500|     2020|   09/07/2021|        Avon|        245 NEW ROAD|     217640.00|  400000.00|     0.5441|  Residential|   Single Family|         2021|\n",
      "|       200121|     2020|   12/15/2020|        Avon|        63 NORTHGATE|     528490.00|  775000.00|     0.6819|  Residential|   Single Family|         2020|\n",
      "|        20058|     2020|   06/01/2021| Barkhamsted|    46 RATLUM MTN RD|     203530.00|  415000.00|0.490433735|  Residential|   Single Family|         2021|\n",
      "|       200046|     2020|   01/25/2021|Beacon Falls|       34 LASKY ROAD|     158030.00|  243000.00|     0.6503|  Residential|   Single Family|         2021|\n",
      "|       200016|     2020|   11/13/2020|Beacon Falls|        9 AVON COURT|      65590.00|  100000.00|     0.6559|  Residential|           Condo|         2020|\n",
      "|      2020360|     2020|   08/10/2021|      Berlin|     94 PERCIVAL AVE|     140600.00|  190790.00|     0.7369|  Residential|   Single Family|         2021|\n",
      "|        20281|     2020|   04/21/2021|      Bethel|    16 OXFORD STREET|     170800.00|  307000.00|     0.5563|  Residential|   Single Family|         2021|\n",
      "|        20364|     2020|   06/17/2021|      Bethel|1308 LEXINGTON BO...|     195300.00|  365000.00|      0.535|  Residential|           Condo|         2021|\n",
      "|        20423|     2020|   07/21/2021|      Bethel| 10 CASTLE HILL ROAD|     219870.00|  325000.00|     0.6765|  Residential|   Single Family|         2021|\n",
      "|        20097|     2020|   11/25/2020|      Bethel|   8 BLACKMAN AVENUE|     264040.00|  445000.00|     0.5933|  Residential|      Two Family|         2020|\n",
      "|       200008|     2020|   10/21/2020|   Bethlehem|    34 HIGHLAND ROAD|      82000.00|  106000.00|     0.7735|  Residential|   Single Family|         2020|\n",
      "|        20062|     2020|   05/10/2021|      Bolton|    39 STONEHEDGE LN|     189400.00|  273750.00|     0.6918|  Residential|   Single Family|         2021|\n",
      "|       200305|     2020|   02/22/2021|    Branford|49 ROSE ST TOWERS...|      97800.00|  147000.00|     0.6653|  Residential|           Condo|         2021|\n",
      "|       200400|     2020|   04/08/2021|    Branford|         460 MAIN ST|     180500.00|  355000.00|     0.5084|  Residential|      Two Family|         2021|\n",
      "|       200423|     2020|   04/23/2021|    Branford|       24 COLLINS DR|     147000.00|  290000.00|     0.5068|  Residential|   Single Family|         2021|\n",
      "|       200483|     2020|   05/18/2021|    Branford|        61 PALMER RD|     219900.00|  460000.00|      0.478|  Residential|   Single Family|         2021|\n",
      "+-------------+---------+-------------+------------+--------------------+--------------+-----------+-----------+-------------+----------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86833a4c",
   "metadata": {},
   "source": [
    "* Transform the datatype of Assessed Value, Sale Amount and Sales Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c4581299",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import FloatType\n",
    "df = df.withColumn('Assessed Value', df['Assessed Value'].cast(FloatType()))\\\n",
    ".withColumn('Sale Amount',df['Sale Amount'].cast(FloatType()))\\\n",
    ".withColumn('Sales Ratio',df['Sales Ratio'].cast(FloatType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccf5f08",
   "metadata": {},
   "source": [
    "* We cloud find some values of the property type are wrongly replaced by the residental type and vice versa. For single/two/three/four family under property type, we should replace them with 'residential'. And for 'condo' under residental type should be filled with NULL. Another point that needs to be aware of is the null values in 'Residential Type' are caused by their corresponding 'Property Type'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "cf632057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace '-family' by 'residential'\n",
    "df=df.withColumn('Property Type', when((df['Property Type']=='Single Family')|(df['Property Type']=='Two Family')|(df['Property Type']=='Three Family')|(df['Property Type']=='Four Family'),\\\n",
    "                                     'Residential').otherwise(df['Property Type']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a430f06a",
   "metadata": {},
   "source": [
    "# Answer the questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6555c5",
   "metadata": {},
   "source": [
    "### Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f25ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.function import mean,median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "770eccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "town_mean = df.groupBy('Town','Recorded Year').mean('Sale Amount').orderBy('Town','Recorded Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d8a6cc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+------------------+\n",
      "|         Town|Recorded Year|  avg(Sale Amount)|\n",
      "+-------------+-------------+------------------+\n",
      "|***Unknown***|         2007|          282450.0|\n",
      "|      Andover|         2002|284210.92307692306|\n",
      "|      Andover|         2003|154602.83333333334|\n",
      "|      Andover|         2004|201707.20547945207|\n",
      "|      Andover|         2005|229664.86075949366|\n",
      "|      Andover|         2006|252078.26086956522|\n",
      "|      Andover|         2007|          271452.5|\n",
      "|      Andover|         2008|252309.69696969696|\n",
      "|      Andover|         2009|229246.66666666666|\n",
      "|      Andover|         2010|204887.46511627908|\n",
      "|      Andover|         2011|194305.70967741936|\n",
      "|      Andover|         2012|206381.53846153847|\n",
      "|      Andover|         2013|203245.11111111112|\n",
      "|      Andover|         2014|          198186.0|\n",
      "|      Andover|         2015|  179958.568627451|\n",
      "|      Andover|         2016|222121.19512195123|\n",
      "|      Andover|         2017|211357.14285714287|\n",
      "|      Andover|         2018|199060.50588474027|\n",
      "|      Andover|         2019|251278.01408450704|\n",
      "|      Andover|         2020| 256468.3962264151|\n",
      "+-------------+-------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "town_mean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "badc5031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+-------------------+\n",
      "|         Town|Recorded Year|median(Sale Amount)|\n",
      "+-------------+-------------+-------------------+\n",
      "|***Unknown***|         2007|           282450.0|\n",
      "|      Andover|         2002|           235000.0|\n",
      "|      Andover|         2003|           150000.0|\n",
      "|      Andover|         2004|           175000.0|\n",
      "|      Andover|         2005|           220000.0|\n",
      "|      Andover|         2006|           240000.0|\n",
      "|      Andover|         2007|           274500.0|\n",
      "|      Andover|         2008|           239000.0|\n",
      "|      Andover|         2009|           228390.0|\n",
      "|      Andover|         2010|           211250.0|\n",
      "|      Andover|         2011|           178000.0|\n",
      "|      Andover|         2012|           209000.0|\n",
      "|      Andover|         2013|           206250.0|\n",
      "|      Andover|         2014|           198000.0|\n",
      "|      Andover|         2015|           170000.0|\n",
      "|      Andover|         2016|           222000.0|\n",
      "|      Andover|         2017|           193500.0|\n",
      "|      Andover|         2018|           183900.0|\n",
      "|      Andover|         2019|           245000.0|\n",
      "|      Andover|         2020|           257500.0|\n",
      "+-------------+-------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import percentile_approx\n",
    "town_median = df.groupBy('Town','Recorded Year').agg(median(\"Sale Amount\")).orderBy('Town','Recorded Year')\n",
    "town_median.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2b78843f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+-------------------+\n",
      "|         Town|Recorded Year|stddev(Sale Amount)|\n",
      "+-------------+-------------+-------------------+\n",
      "|***Unknown***|         2007|               NULL|\n",
      "|      Andover|         2002| 199270.09482377663|\n",
      "|      Andover|         2003| 105343.62275195896|\n",
      "|      Andover|         2004|  119560.4046566652|\n",
      "|      Andover|         2005| 143547.02159024088|\n",
      "|      Andover|         2006| 127904.98541763722|\n",
      "|      Andover|         2007| 105956.51673510396|\n",
      "|      Andover|         2008| 111145.04604020956|\n",
      "|      Andover|         2009| 125761.11402178335|\n",
      "|      Andover|         2010| 102981.45777837613|\n",
      "|      Andover|         2011| 135185.65483146836|\n",
      "|      Andover|         2012| 114011.94716974135|\n",
      "|      Andover|         2013| 106682.94442821221|\n",
      "|      Andover|         2014| 117965.02610025284|\n",
      "|      Andover|         2015| 126652.08301015105|\n",
      "|      Andover|         2016| 132963.55830099076|\n",
      "|      Andover|         2017| 151861.45363093656|\n",
      "|      Andover|         2018| 124216.25304154328|\n",
      "|      Andover|         2019| 136935.28081913033|\n",
      "|      Andover|         2020| 132978.15064605098|\n",
      "+-------------+-------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import stddev\n",
    "town_std = df.groupBy('Town','Recorded Year').agg(stddev('Sale Amount')).orderBy('Town', 'Recorded Year')\n",
    "town_std.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "46f8291d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+-------------------+\n",
      "|         Town|Recorded Year|avg(Assessed Value)|\n",
      "+-------------+-------------+-------------------+\n",
      "|***Unknown***|         2007|            66540.0|\n",
      "|      Andover|         2002| 161669.23076923078|\n",
      "|      Andover|         2003|  79024.58333333333|\n",
      "|      Andover|         2004|  88524.65753424658|\n",
      "|      Andover|         2005|  91106.70886075949|\n",
      "|      Andover|         2006|  96660.21739130435|\n",
      "|      Andover|         2007| 178008.33333333334|\n",
      "|      Andover|         2008| 171654.84848484848|\n",
      "|      Andover|         2009| 163170.27777777778|\n",
      "|      Andover|         2010|  165237.2093023256|\n",
      "|      Andover|         2011| 150816.12903225806|\n",
      "|      Andover|         2012| 169721.53846153847|\n",
      "|      Andover|         2013|           150735.0|\n",
      "|      Andover|         2014| 144927.56756756757|\n",
      "|      Andover|         2015| 143228.03921568627|\n",
      "|      Andover|         2016| 162535.60975609755|\n",
      "|      Andover|         2017|  158125.7142857143|\n",
      "|      Andover|         2018| 137404.93506493507|\n",
      "|      Andover|         2019| 165287.18309859154|\n",
      "|      Andover|         2020| 163366.03773584907|\n",
      "+-------------+-------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "town_mean2 = df.groupBy('Town','Recorded Year').mean('Assessed Value').orderBy('Town','Recorded Year')\n",
    "town_mean2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "824fc8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+----------------------+\n",
      "|         Town|Recorded Year|median(Assessed Value)|\n",
      "+-------------+-------------+----------------------+\n",
      "|***Unknown***|         2007|               66540.0|\n",
      "|      Andover|         2002|              125400.0|\n",
      "|      Andover|         2003|               79950.0|\n",
      "|      Andover|         2004|               76700.0|\n",
      "|      Andover|         2005|               84300.0|\n",
      "|      Andover|         2006|               87960.0|\n",
      "|      Andover|         2007|              190300.0|\n",
      "|      Andover|         2008|              158600.0|\n",
      "|      Andover|         2009|              163900.0|\n",
      "|      Andover|         2010|              160000.0|\n",
      "|      Andover|         2011|              139100.0|\n",
      "|      Andover|         2012|              175200.0|\n",
      "|      Andover|         2013|              155900.0|\n",
      "|      Andover|         2014|              139400.0|\n",
      "|      Andover|         2015|              142200.0|\n",
      "|      Andover|         2016|              141900.0|\n",
      "|      Andover|         2017|              132200.0|\n",
      "|      Andover|         2018|              128800.0|\n",
      "|      Andover|         2019|              156500.0|\n",
      "|      Andover|         2020|              157700.0|\n",
      "+-------------+-------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "town_median2 = df.groupBy('Town','Recorded Year').agg(median(\"Assessed Value\")).orderBy('Town','Recorded Year')\n",
    "town_median2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6acf26a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+----------------------+\n",
      "|         Town|Recorded Year|stddev(Assessed Value)|\n",
      "+-------------+-------------+----------------------+\n",
      "|***Unknown***|         2007|                  NULL|\n",
      "|      Andover|         2002|    135084.32171928382|\n",
      "|      Andover|         2003|    49172.108833645594|\n",
      "|      Andover|         2004|     50734.42229673918|\n",
      "|      Andover|         2005|     56624.53211945759|\n",
      "|      Andover|         2006|    45160.999422516994|\n",
      "|      Andover|         2007|     72526.36458975496|\n",
      "|      Andover|         2008|      72568.4243542436|\n",
      "|      Andover|         2009|     83020.51366073366|\n",
      "|      Andover|         2010|     68614.82216400481|\n",
      "|      Andover|         2011|     95810.63561969236|\n",
      "|      Andover|         2012|      80866.1591608993|\n",
      "|      Andover|         2013|     64702.30455158234|\n",
      "|      Andover|         2014|     77566.80566544647|\n",
      "|      Andover|         2015|     72367.35236333046|\n",
      "|      Andover|         2016|     79225.12410999369|\n",
      "|      Andover|         2017|     67987.86755051179|\n",
      "|      Andover|         2018|     74232.46785079567|\n",
      "|      Andover|         2019|     81593.43125142051|\n",
      "|      Andover|         2020|     87865.00122214635|\n",
      "+-------------+-------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "town_std2 = df.groupBy('Town','Recorded Year').agg(stddev('Assessed Value')).orderBy('Town', 'Recorded Year')\n",
    "town_std2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34aee4f",
   "metadata": {},
   "source": [
    "### Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e9d2e9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+\n",
      "|Recorded Year|  avg(Sale Amount)|\n",
      "+-------------+------------------+\n",
      "|         1999|           95000.0|\n",
      "|         2001|226185.16325078282|\n",
      "|         2002|260854.30521423675|\n",
      "|         2003| 306830.5820477609|\n",
      "|         2004|342060.22166938556|\n",
      "|         2005|382262.65993572713|\n",
      "|         2006| 378258.5531620519|\n",
      "|         2007| 482261.8273617049|\n",
      "|         2008|413001.73154539074|\n",
      "|         2009| 324366.5452291758|\n",
      "|         2010|353688.21416888165|\n",
      "|         2011| 344237.6026551982|\n",
      "|         2012|399355.64255664364|\n",
      "|         2013| 410089.9408392876|\n",
      "|         2014|395638.27309792326|\n",
      "|         2015| 391299.6584585404|\n",
      "|         2016|477925.68572388735|\n",
      "|         2017| 390925.8406875954|\n",
      "|         2018| 391932.8820067275|\n",
      "|         2019| 396059.7142524483|\n",
      "+-------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "overall_mean = df.groupBy('Recorded Year').mean(\"Sale Amount\").orderBy(\"Recorded Year\")\n",
    "overall_mean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "decad812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+\n",
      "|Recorded Year|median(Sale Amount)|\n",
      "+-------------+-------------------+\n",
      "|         1999|            95000.0|\n",
      "|         2001|           155000.0|\n",
      "|         2002|           170000.0|\n",
      "|         2003|           190000.0|\n",
      "|         2004|           215000.0|\n",
      "|         2005|           242000.0|\n",
      "|         2006|           250000.0|\n",
      "|         2007|           265000.0|\n",
      "|         2008|           238000.0|\n",
      "|         2009|           212000.0|\n",
      "|         2010|           219000.0|\n",
      "|         2011|           206041.0|\n",
      "|         2012|           215000.0|\n",
      "|         2013|           218000.0|\n",
      "|         2014|           207500.0|\n",
      "|         2015|           211000.0|\n",
      "|         2016|           214500.0|\n",
      "|         2017|           225000.0|\n",
      "|         2018|           225000.0|\n",
      "|         2019|           229000.0|\n",
      "+-------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "overall_median = df.groupBy('Recorded Year').agg(median(\"Sale Amount\")).orderBy(\"Recorded Year\")\n",
    "overall_median.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4b070bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+\n",
      "|Recorded Year|stddev(Sale Amount)|\n",
      "+-------------+-------------------+\n",
      "|         1999|               NULL|\n",
      "|         2001| 418202.49171399575|\n",
      "|         2002|  626407.8689015368|\n",
      "|         2003|  833582.2807630944|\n",
      "|         2004|  919108.1974434166|\n",
      "|         2005| 1015938.5524322496|\n",
      "|         2006| 1014153.2545975755|\n",
      "|         2007| 1861559.6734854968|\n",
      "|         2008|  1388032.524565023|\n",
      "|         2009|  903942.9310424727|\n",
      "|         2010|  929676.9326805144|\n",
      "|         2011|  954261.4768950193|\n",
      "|         2012| 1020104.6043999388|\n",
      "|         2013| 2094858.4983431017|\n",
      "|         2014| 1654366.6915424864|\n",
      "|         2015| 1309204.8279953485|\n",
      "|         2016|  5682554.390183069|\n",
      "|         2017| 1337240.3364326854|\n",
      "|         2018| 1493382.4209400553|\n",
      "|         2019| 2114988.2635969813|\n",
      "+-------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "overall_std = df.groupBy('Recorded Year').agg(stddev(\"Sale Amount\")).orderBy(\"Recorded Year\")\n",
    "overall_std.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d5f49a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+\n",
      "|Recorded Year|avg(Assessed Value)|\n",
      "+-------------+-------------------+\n",
      "|         1999|            46690.0|\n",
      "|         2001|  134720.4057073726|\n",
      "|         2002| 149173.23510038952|\n",
      "|         2003| 179624.00463697812|\n",
      "|         2004| 195381.13817292007|\n",
      "|         2005|  209805.0703585617|\n",
      "|         2006|  220475.7717998564|\n",
      "|         2007|  347193.7450682524|\n",
      "|         2008|  325793.0107627515|\n",
      "|         2009| 294442.42692265316|\n",
      "|         2010|  342126.0990850542|\n",
      "|         2011| 330744.58772749937|\n",
      "|         2012| 402571.37259600614|\n",
      "|         2013| 354097.83864775515|\n",
      "|         2014| 322815.66665077134|\n",
      "|         2015|  306143.9597087577|\n",
      "|         2016|  307743.6125685241|\n",
      "|         2017|  319764.2016461754|\n",
      "|         2018| 323368.53689421463|\n",
      "|         2019| 306572.08927824866|\n",
      "+-------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "overall_mean2 = df.groupBy('Recorded Year').mean(\"Assessed Value\").orderBy(\"Recorded Year\")\n",
    "overall_mean2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a7814c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------------+\n",
      "|Recorded Year|median(Assessed Value)|\n",
      "+-------------+----------------------+\n",
      "|         1999|               46690.0|\n",
      "|         2001|               88340.0|\n",
      "|         2002|               89060.0|\n",
      "|         2003|               94200.0|\n",
      "|         2004|               99820.0|\n",
      "|         2005|              105070.0|\n",
      "|         2006|              111000.0|\n",
      "|         2007|              147350.0|\n",
      "|         2008|              159390.0|\n",
      "|         2009|              164630.0|\n",
      "|         2010|              174825.0|\n",
      "|         2011|              175195.0|\n",
      "|         2012|              180975.0|\n",
      "|         2013|              167185.0|\n",
      "|         2014|              156590.0|\n",
      "|         2015|              156000.0|\n",
      "|         2016|              151550.0|\n",
      "|         2017|              154630.0|\n",
      "|         2018|              151050.0|\n",
      "|         2019|              149525.0|\n",
      "+-------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "overall_median2 = df.groupBy('Recorded Year').agg(median(\"Assessed Value\")).orderBy(\"Recorded Year\")\n",
    "overall_median2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "befa2005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------------+\n",
      "|Recorded Year|stddev(Assessed Value)|\n",
      "+-------------+----------------------+\n",
      "|         1999|                  NULL|\n",
      "|         2001|     356032.9475844128|\n",
      "|         2002|     559916.3273440142|\n",
      "|         2003|     836184.8050523478|\n",
      "|         2004|     903839.9807607078|\n",
      "|         2005|     958885.7397193818|\n",
      "|         2006|     989478.5830095297|\n",
      "|         2007|    1875132.0147201566|\n",
      "|         2008|     1528656.899132062|\n",
      "|         2009|    1337422.4562338851|\n",
      "|         2010|    1608151.1108565175|\n",
      "|         2011|    1391879.1996660284|\n",
      "|         2012|     1947199.472071419|\n",
      "|         2013|    1828785.5199577147|\n",
      "|         2014|    1634386.0328331415|\n",
      "|         2015|     1664666.796759817|\n",
      "|         2016|    1458037.3091694487|\n",
      "|         2017|    1604641.0599327646|\n",
      "|         2018|     4335742.734808294|\n",
      "|         2019|    1774574.6747978753|\n",
      "+-------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "overall_stddev2 = df.groupBy('Recorded Year').agg(stddev(\"Assessed Value\")).orderBy(\"Recorded Year\")\n",
    "overall_stddev2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd4ef54",
   "metadata": {},
   "source": [
    "### Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "7ffe8c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+------------------+\n",
      "|Property type|Recorded Year|  avg(Sale Amount)|\n",
      "+-------------+-------------+------------------+\n",
      "|         NULL|         2001| 226104.4569984337|\n",
      "|         NULL|         2002|260854.30521423675|\n",
      "|         NULL|         2003| 306833.2203673979|\n",
      "|         NULL|         2004|342053.01011501753|\n",
      "|         NULL|         2005| 382270.3247422028|\n",
      "|         NULL|         2006|380201.39923682326|\n",
      "|         NULL|         2007| 864805.8138225587|\n",
      "|         NULL|         2008| 815274.2875399361|\n",
      "|         NULL|         2009| 551686.1516853933|\n",
      "|         NULL|         2010| 532340.3656607091|\n",
      "|         NULL|         2011| 684217.3513767209|\n",
      "|         NULL|         2012| 694679.6584899649|\n",
      "|         NULL|         2013| 995697.3873517787|\n",
      "|         NULL|         2014| 981529.6213110472|\n",
      "|         NULL|         2015| 1067359.834344967|\n",
      "|         NULL|         2016| 1993195.544529262|\n",
      "|         NULL|         2017| 870635.3879443586|\n",
      "|         NULL|         2018| 972535.2576280998|\n",
      "|         NULL|         2019|1231115.2426517329|\n",
      "|         NULL|         2020| 747061.5576594716|\n",
      "+-------------+-------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pt_mean = df.groupBy('Property type','Recorded Year').mean(\"Sale Amount\").orderBy('Property type','Recorded Year')\n",
    "pt_mean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "7804fb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+-------------------+\n",
      "|Property type|Recorded Year|median(Sale Amount)|\n",
      "+-------------+-------------+-------------------+\n",
      "|         NULL|         2001|           155000.0|\n",
      "|         NULL|         2002|           170000.0|\n",
      "|         NULL|         2003|           190000.0|\n",
      "|         NULL|         2004|           215000.0|\n",
      "|         NULL|         2005|           242000.0|\n",
      "|         NULL|         2006|           249500.0|\n",
      "|         NULL|         2007|           190000.0|\n",
      "|         NULL|         2008|           170000.0|\n",
      "|         NULL|         2009|           150000.0|\n",
      "|         NULL|         2010|           150000.0|\n",
      "|         NULL|         2011|           165000.0|\n",
      "|         NULL|         2012|           155000.0|\n",
      "|         NULL|         2013|           152900.0|\n",
      "|         NULL|         2014|           165000.0|\n",
      "|         NULL|         2015|           182873.5|\n",
      "|         NULL|         2016|           160000.0|\n",
      "|         NULL|         2017|           150000.0|\n",
      "|         NULL|         2018|           183000.0|\n",
      "|         NULL|         2019|           172800.0|\n",
      "|         NULL|         2020|           162500.0|\n",
      "+-------------+-------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pt_median = df.groupBy('Property type','Recorded Year').agg(median(\"Sale Amount\")).orderBy('Property type','Recorded Year')\n",
    "pt_median.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "4a7aecef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+-------------------+\n",
      "|Property type|Recorded Year|avg(Assessed Value)|\n",
      "+-------------+-------------+-------------------+\n",
      "|         NULL|         2001| 134649.27958137548|\n",
      "|         NULL|         2002| 149173.23510038952|\n",
      "|         NULL|         2003| 179625.70650971998|\n",
      "|         NULL|         2004| 195375.41988199146|\n",
      "|         NULL|         2005| 209809.00134117797|\n",
      "|         NULL|         2006|  223843.9949699716|\n",
      "|         NULL|         2007|  1082298.562220928|\n",
      "|         NULL|         2008| 1059974.8408364798|\n",
      "|         NULL|         2009|  883719.4922752809|\n",
      "|         NULL|         2010| 1062359.6481101671|\n",
      "|         NULL|         2011|  965773.1498748435|\n",
      "|         NULL|         2012| 1395873.1704364447|\n",
      "|         NULL|         2013| 1264727.4095469748|\n",
      "|         NULL|         2014| 1193620.8404283102|\n",
      "|         NULL|         2015|  1148941.043500253|\n",
      "|         NULL|         2016| 1392330.5450381679|\n",
      "|         NULL|         2017| 1065898.2869654817|\n",
      "|         NULL|         2018| 1015362.1539220522|\n",
      "|         NULL|         2019| 1348509.8062704727|\n",
      "|         NULL|         2020|   840237.841826215|\n",
      "+-------------+-------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pt_mean2 = df.groupBy('Property type','Recorded Year').mean(\"Assessed Value\").orderBy('Property type','Recorded Year')\n",
    "pt_mean2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "052dbd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+----------------------+\n",
      "|Property type|Recorded Year|median(Assessed Value)|\n",
      "+-------------+-------------+----------------------+\n",
      "|         NULL|         2001|               88340.0|\n",
      "|         NULL|         2002|               89060.0|\n",
      "|         NULL|         2003|               94205.0|\n",
      "|         NULL|         2004|               99820.0|\n",
      "|         NULL|         2005|              105070.0|\n",
      "|         NULL|         2006|              105300.0|\n",
      "|         NULL|         2007|              107580.0|\n",
      "|         NULL|         2008|              126620.0|\n",
      "|         NULL|         2009|              133380.0|\n",
      "|         NULL|         2010|              150080.0|\n",
      "|         NULL|         2011|              174680.0|\n",
      "|         NULL|         2012|              174100.0|\n",
      "|         NULL|         2013|              145950.0|\n",
      "|         NULL|         2014|              163030.0|\n",
      "|         NULL|         2015|              163595.0|\n",
      "|         NULL|         2016|              157600.0|\n",
      "|         NULL|         2017|              141255.0|\n",
      "|         NULL|         2018|              150225.0|\n",
      "|         NULL|         2019|              151880.0|\n",
      "|         NULL|         2020|              113330.0|\n",
      "+-------------+-------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pt_median2 = df.groupBy('Property type','Recorded Year').agg(median(\"Assessed Value\")).orderBy('Property type','Recorded Year')\n",
    "pt_median2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632b38bd",
   "metadata": {},
   "source": [
    "### Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "4a4c71fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+------------------+\n",
      "|Residential type|Recorded Year|  avg(Sale Amount)|\n",
      "+----------------+-------------+------------------+\n",
      "|            NULL|         2001| 226104.4569984337|\n",
      "|            NULL|         2002|260854.30521423675|\n",
      "|            NULL|         2003| 306833.2203673979|\n",
      "|            NULL|         2004|342053.01011501753|\n",
      "|            NULL|         2005| 382270.3247422028|\n",
      "|            NULL|         2006|380201.39923682326|\n",
      "|            NULL|         2007| 864805.8138225587|\n",
      "|            NULL|         2008| 815274.2875399361|\n",
      "|            NULL|         2009| 551686.1516853933|\n",
      "|            NULL|         2010| 532340.3656607091|\n",
      "|            NULL|         2011| 684217.3513767209|\n",
      "|            NULL|         2012| 694679.6584899649|\n",
      "|            NULL|         2013| 995697.3873517787|\n",
      "|            NULL|         2014| 981529.6213110472|\n",
      "|            NULL|         2015| 1067359.834344967|\n",
      "|            NULL|         2016| 1993195.544529262|\n",
      "|            NULL|         2017| 870635.3879443586|\n",
      "|            NULL|         2018| 972535.2576280998|\n",
      "|            NULL|         2019|1231115.2426517329|\n",
      "|            NULL|         2020|  824861.917697801|\n",
      "+----------------+-------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------------+-------------+-------------------+\n",
      "|Residential type|Recorded Year|median(Sale Amount)|\n",
      "+----------------+-------------+-------------------+\n",
      "|            NULL|         2001|           155000.0|\n",
      "|            NULL|         2002|           170000.0|\n",
      "|            NULL|         2003|           190000.0|\n",
      "|            NULL|         2004|           215000.0|\n",
      "|            NULL|         2005|           242000.0|\n",
      "|            NULL|         2006|           249500.0|\n",
      "|            NULL|         2007|           190000.0|\n",
      "|            NULL|         2008|           170000.0|\n",
      "|            NULL|         2009|           150000.0|\n",
      "|            NULL|         2010|           150000.0|\n",
      "|            NULL|         2011|           165000.0|\n",
      "|            NULL|         2012|           155000.0|\n",
      "|            NULL|         2013|           152900.0|\n",
      "|            NULL|         2014|           165000.0|\n",
      "|            NULL|         2015|           182873.5|\n",
      "|            NULL|         2016|           160000.0|\n",
      "|            NULL|         2017|           150000.0|\n",
      "|            NULL|         2018|           183000.0|\n",
      "|            NULL|         2019|           172800.0|\n",
      "|            NULL|         2020|           165000.0|\n",
      "+----------------+-------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------------+-------------+-------------------+\n",
      "|Residential type|Recorded Year|avg(Assessed Value)|\n",
      "+----------------+-------------+-------------------+\n",
      "|            NULL|         2001| 134649.27958137548|\n",
      "|            NULL|         2002| 149173.23510038952|\n",
      "|            NULL|         2003| 179625.70650971998|\n",
      "|            NULL|         2004| 195375.41988199146|\n",
      "|            NULL|         2005| 209809.00134117797|\n",
      "|            NULL|         2006|  223843.9949699716|\n",
      "|            NULL|         2007|  1082298.562220928|\n",
      "|            NULL|         2008| 1059974.8408364798|\n",
      "|            NULL|         2009|  883719.4922752809|\n",
      "|            NULL|         2010| 1062359.6481101671|\n",
      "|            NULL|         2011|  965773.1498748435|\n",
      "|            NULL|         2012| 1395873.1704364447|\n",
      "|            NULL|         2013| 1264727.4095469748|\n",
      "|            NULL|         2014| 1193620.8404283102|\n",
      "|            NULL|         2015|  1148941.043500253|\n",
      "|            NULL|         2016| 1392330.5450381679|\n",
      "|            NULL|         2017| 1065898.2869654817|\n",
      "|            NULL|         2018| 1015362.1539220522|\n",
      "|            NULL|         2019| 1348509.8062704727|\n",
      "|            NULL|         2020|  795360.5142497905|\n",
      "+----------------+-------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------------+-------------+----------------------+\n",
      "|Residential type|Recorded Year|median(Assessed Value)|\n",
      "+----------------+-------------+----------------------+\n",
      "|            NULL|         2001|               88340.0|\n",
      "|            NULL|         2002|               89060.0|\n",
      "|            NULL|         2003|               94205.0|\n",
      "|            NULL|         2004|               99820.0|\n",
      "|            NULL|         2005|              105070.0|\n",
      "|            NULL|         2006|              105300.0|\n",
      "|            NULL|         2007|              107580.0|\n",
      "|            NULL|         2008|              126620.0|\n",
      "|            NULL|         2009|              133380.0|\n",
      "|            NULL|         2010|              150080.0|\n",
      "|            NULL|         2011|              174680.0|\n",
      "|            NULL|         2012|              174100.0|\n",
      "|            NULL|         2013|              145950.0|\n",
      "|            NULL|         2014|              163030.0|\n",
      "|            NULL|         2015|              163595.0|\n",
      "|            NULL|         2016|              157600.0|\n",
      "|            NULL|         2017|              141255.0|\n",
      "|            NULL|         2018|              150225.0|\n",
      "|            NULL|         2019|              151880.0|\n",
      "|            NULL|         2020|              112580.0|\n",
      "+----------------+-------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rt_mean = df.groupBy('Residential type','Recorded Year').mean(\"Sale Amount\").orderBy('Residential type','Recorded Year')\n",
    "rt_mean.show()\n",
    "rt_median = df.groupBy('Residential type','Recorded Year').agg(median(\"Sale Amount\")).orderBy('Residential type','Recorded Year')\n",
    "rt_median.show()\n",
    "rt_mean2 = df.groupBy('Residential type','Recorded Year').mean(\"Assessed Value\").orderBy('Residential type','Recorded Year')\n",
    "rt_mean2.show()\n",
    "rt_median2 = df.groupBy('Residential type','Recorded Year').agg(median(\"Assessed Value\")).orderBy('Residential type','Recorded Year')\n",
    "rt_median2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "3be0093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to file \n",
    "town_mean.toPandas().to_csv('townmean.csv')\n",
    "town_median.toPandas().to_csv('townmedian.csv')\n",
    "town_std.toPandas().to_csv('townstd.csv')\n",
    "\n",
    "town_mean2.toPandas().to_csv('townmean2.csv')\n",
    "town_median2.toPandas().to_csv('townmedian2.csv')\n",
    "town_std2.toPandas().to_csv('townstd2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "a6ccede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_mean.toPandas().to_csv('overallmean.csv')\n",
    "overall_median.toPandas().to_csv('overallmedian.csv')\n",
    "overall_std.toPandas().to_csv('overallstd.csv')\n",
    "\n",
    "overall_mean2.toPandas().to_csv('overallmean2.csv')\n",
    "overall_median2.toPandas().to_csv('overallmedian2.csv')\n",
    "overall_stddev2.toPandas().to_csv('overallstd2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "008f34e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_mean.toPandas().to_csv('ptmean.csv')\n",
    "pt_median.toPandas().to_csv('ptmedian.csv')\n",
    "\n",
    "pt_mean2.toPandas().to_csv('ptmean2.csv')\n",
    "pt_median2.toPandas().to_csv('ptmedian2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "dd29509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_mean.toPandas().to_csv('rtmean.csv')\n",
    "rt_median.toPandas().to_csv('rtmedian.csv')\n",
    "rt_mean2.toPandas().to_csv('rtmean2.csv')\n",
    "rt_median2.toPandas().to_csv('rtmedian2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f795c3a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
